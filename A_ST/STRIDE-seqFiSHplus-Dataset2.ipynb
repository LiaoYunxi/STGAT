{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d82260d2-2f2d-40ed-bbd4-775f8af1c05f",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# function #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "465c34b6-a530-456d-83c4-4f7a1fbca7b3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import logging\n",
    "import sys\n",
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import h5py\n",
    "import tables\n",
    "import argparse as ap\n",
    "\n",
    "import scipy\n",
    "import scipy.sparse as sp_sparse\n",
    "import scipy.stats as ss\n",
    "\n",
    "import collections\n",
    "from collections import defaultdict\n",
    "\n",
    "import gensim\n",
    "from gensim.models import LdaModel\n",
    "from gensim.models import CoherenceModel\n",
    "from gensim.corpora.dictionary import Dictionary\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics.cluster import normalized_mutual_info_score\n",
    "\n",
    "from ModelEvaluate import *\n",
    "from ModelTrain import *\n",
    "from Deconvolution import *\n",
    "#import stride"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3080178-d885-461e-96b8-0e024cf216ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def setup_seed(seed):\n",
    "    np.random.seed(seed)\n",
    "    random.seed(seed)\n",
    "    # torch.manual_seed(seed)\n",
    "    # torch.cuda.manual_seed_all(seed)\n",
    "    # torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "77fb4637-eff9-4970-ad33-4e580ee48587",
   "metadata": {},
   "outputs": [],
   "source": [
    "import scanpy as sc\n",
    "import anndata\n",
    "\n",
    "def MarkerFind(sc_count_mat, sc_count_genes, sc_count_cells, sc_anno_file, ntop = 200):\n",
    "    '''\n",
    "    Find markers for each celltype\n",
    "    '''\n",
    "    adata = anndata.AnnData(sc_count_mat.transpose(), obs = dict(obs_names = sc_count_cells), var = dict(var_names = sc_count_genes))\n",
    "    # preprocess\n",
    "    sc.pp.filter_cells(adata, min_genes = 200)\n",
    "    sc.pp.filter_genes(adata, min_cells = 10)\n",
    "    sc.pp.calculate_qc_metrics(adata, inplace = True)\n",
    "    # normalize data\n",
    "    sc.pp.normalize_total(adata, target_sum=1e4)\n",
    "    sc.pp.log1p(adata)\n",
    "    sc.pp.highly_variable_genes(adata, n_top_genes = 2000)\n",
    "    # add celltype info\n",
    "    meta_data = pd.read_csv(sc_anno_file, sep = \"\\t\", header = None, index_col = 0)\n",
    "    meta_data.columns = [\"Celltype\"]\n",
    "    adata.obs[\"Celltype\"] = meta_data.loc[adata.obs.index, \"Celltype\"]\n",
    "    # find marker genes for each cell-type\n",
    "    sc.tl.rank_genes_groups(adata, groupby = 'Celltype', method='wilcoxon', pts = True, use_raw = False, tie_correct = True)\n",
    "    top_marker_df = pd.DataFrame(adata.uns['rank_genes_groups']['names']).iloc[0:ntop,]\n",
    "    top_marker_array = np.array(top_marker_df.T)\n",
    "    top_marker_list = list(set(top_marker_array.flatten().tolist()))\n",
    "    return(top_marker_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ba3ac3c8-e27a-4f2c-ad00-ff7950abed59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "FeatureBCMatrix = collections.namedtuple('FeatureBCMatrix', ['ids', 'names', 'barcodes', 'matrix'])\n",
    "def read_10X_h5(filename):\n",
    "    \"\"\"Read 10X HDF5 files, support both gene expression and peaks.\"\"\"\n",
    "    with tables.open_file(filename, 'r') as f:\n",
    "        try:\n",
    "            group = f.get_node(f.root, 'matrix')\n",
    "        except tables.NoSuchNodeError:\n",
    "            print(\"Matrix group does not exist in this file.\")\n",
    "            return None\n",
    "        feature_group = getattr(group, 'features')\n",
    "        ids = getattr(feature_group, 'id').read()\n",
    "        names = getattr(feature_group, 'name').read()\n",
    "        barcodes = getattr(group, 'barcodes').read()\n",
    "        data = getattr(group, 'data').read()\n",
    "        indices = getattr(group, 'indices').read()\n",
    "        indptr = getattr(group, 'indptr').read()\n",
    "        shape = getattr(group, 'shape').read()\n",
    "        matrix = sp_sparse.csc_matrix((data, indices, indptr), shape=shape)\n",
    "        return FeatureBCMatrix(ids, names, barcodes, matrix)\n",
    "\n",
    "def write_10X_h5(filename, matrix, features, barcodes):\n",
    "    \"\"\"Write 10X HDF5 files, support both gene expression and peaks.\"\"\"\n",
    "    f = h5py.File(filename, 'w')\n",
    "    datatype = \"Gene\"\n",
    "    M = sp_sparse.csc_matrix(matrix, dtype=np.float32)\n",
    "    B = np.array(barcodes, dtype='|S200')\n",
    "    P = np.array(features, dtype='|S100')\n",
    "    FT = np.array([datatype]*len(features), dtype='|S100')\n",
    "    mat = f.create_group('matrix')\n",
    "    mat.create_dataset('barcodes', data=B)\n",
    "    mat.create_dataset('data', data=M.data)\n",
    "    mat.create_dataset('indices', data=M.indices)\n",
    "    mat.create_dataset('indptr', data=M.indptr)\n",
    "    mat.create_dataset('shape', data=M.shape)\n",
    "    fet = mat.create_group('features')\n",
    "    fet.create_dataset('id', data=P)\n",
    "    fet.create_dataset('name', data=P)\n",
    "    f.close()\n",
    "    \n",
    "def read_count(count_file, separator = \"tab\"):\n",
    "    \"\"\"Read count table as matrix.\"\"\"\n",
    "\n",
    "    if separator == \"tab\":\n",
    "        sep = \"\\t\"\n",
    "    elif separator == \"space\":\n",
    "        sep = \" \"\n",
    "    elif separator == \"comma\":\n",
    "        sep = \",\"\n",
    "    else:\n",
    "        raise Exception(\"Invalid separator!\")\n",
    "\n",
    "    infile = open(count_file, 'r').readlines()\n",
    "    barcodes = infile[0].strip().split(sep)\n",
    "    features = []\n",
    "    matrix = []\n",
    "    for line in infile[1:]:\n",
    "        line = line.strip().split(sep)\n",
    "        features.append(line[0])\n",
    "        matrix.append([float(t) for t in line[1:]])\n",
    "    if len(barcodes) == len(matrix[0]) + 1:\n",
    "        barcodes = barcodes[1:]\n",
    "\n",
    "    return {\"matrix\": matrix, \"features\": features, \"barcodes\": barcodes}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ada420a6-0b6b-45dd-a6ef-7d190be9d34e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def stProcess(st_count_file, st_scale_factor = None):\n",
    "    # read spatial count file\n",
    "    if st_count_file.endswith(\".h5\"):    \n",
    "        st_count = read_10X_h5(st_count_file)\n",
    "        st_count_mat = st_count.matrix\n",
    "        st_count_genes = st_count.names.tolist()\n",
    "        st_count_spots = st_count.barcodes.tolist()\n",
    "        if type(st_count_genes[0]) == bytes:\n",
    "            st_count_genes = [i.decode() for i in st_count_genes]\n",
    "        if type(st_count_spots[0]) == bytes:\n",
    "            st_count_spots = [i.decode() for i in st_count_spots]\n",
    "    else:\n",
    "        st_count = read_count(st_count_file)\n",
    "        st_count_mat = st_count[\"matrix\"]\n",
    "        st_count_mat = sp_sparse.csc_matrix(st_count_mat, dtype=np.float32)\n",
    "        st_count_genes = st_count[\"features\"]\n",
    "        st_count_spots = st_count[\"barcodes\"]\n",
    "    # scale the count matrix\n",
    "    count_per_spot = np.asarray(st_count_mat.sum(axis=0))\n",
    "    count_per_spot = np.array(count_per_spot.tolist()[0])\n",
    "    if not st_scale_factor:\n",
    "        st_scale_factor = np.round(np.quantile(count_per_spot, 0.75)/1000, 0)*1000\n",
    "    r,c = st_count_mat.nonzero()\n",
    "    count_per_spot_sp = sp_sparse.csr_matrix(((1.0/count_per_spot)[c], (r,c)), shape=(st_count_mat.shape))\n",
    "    st_count_scale_mat = st_count_mat.multiply(count_per_spot_sp)*st_scale_factor\n",
    "    st_count_scale_mat = sp_sparse.csc_matrix(st_count_scale_mat)\n",
    "\n",
    "    return({'scale_matrix': st_count_scale_mat, \"raw_matrix\": st_count_mat,\"genes\": st_count_genes, \"spots\": st_count_spots})\n",
    "\n",
    "def scProcess(sc_count_file, sc_anno_file, out_dir, out_prefix, sc_scale_factor = None):\n",
    "    # read scRNA-seq data\n",
    "    if sc_count_file.endswith(\".h5\"):    \n",
    "        sc_count = read_10X_h5(sc_count_file)\n",
    "        sc_count_mat = sc_count.matrix\n",
    "        sc_count_genes = sc_count.names.tolist()\n",
    "        sc_count_cells = sc_count.barcodes.tolist()\n",
    "        if type(sc_count_genes[0]) == bytes:\n",
    "            sc_count_genes = [i.decode() for i in sc_count_genes]\n",
    "        if type(sc_count_cells[0]) == bytes:\n",
    "            sc_count_cells = [i.decode() for i in sc_count_cells]\n",
    "        h5_filename = sc_count_file\n",
    "    else:\n",
    "        sc_count = read_count(sc_count_file)\n",
    "        sc_count_mat = sc_count[\"matrix\"]\n",
    "        sc_count_mat = sp_sparse.csc_matrix(sc_count_mat, dtype=np.float32)\n",
    "        sc_count_genes = sc_count[\"features\"]\n",
    "        sc_count_cells = sc_count[\"barcodes\"]\n",
    "        h5_filename = os.path.join(out_dir, \"%s_scRNA_count.h5\" %(out_prefix))\n",
    "        write_10X_h5(filename = h5_filename, matrix = sc_count_mat,\n",
    "                     features = sc_count_genes, barcodes = sc_count_cells)\n",
    "\n",
    "    # scale the count matrix\n",
    "    count_per_cell = np.asarray(sc_count_mat.sum(axis=0))\n",
    "    count_per_cell = np.array(count_per_cell.tolist()[0])\n",
    "    if not sc_scale_factor:\n",
    "        sc_scale_factor = np.round(np.quantile(count_per_cell, 0.75)/1000, 0)*1000\n",
    "    r,c = sc_count_mat.nonzero()\n",
    "    count_per_cell_sp = sp_sparse.csr_matrix(((1.0/count_per_cell)[c], (r,c)), shape=(sc_count_mat.shape))\n",
    "    sc_count_scale_mat = sc_count_mat.multiply(count_per_cell_sp)*sc_scale_factor\n",
    "    sc_count_scale_mat = sp_sparse.csc_matrix(sc_count_scale_mat)\n",
    "    # read cell-type meta file\n",
    "    cell_celltype_dict = {}\n",
    "    for line in open(sc_anno_file, \"r\"):\n",
    "        items = line.strip().split(\"\\t\")\n",
    "        cell_celltype_dict[items[0]] = items[1]\n",
    "\n",
    "    return({'scale_matrix': sc_count_scale_mat, \"raw_matrix\": sc_count_mat,\n",
    "        \"genes\": sc_count_genes, \"cells\": sc_count_cells, \"cell_celltype\": cell_celltype_dict})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a2f61a60-e40f-40ab-aed8-96c6ea72fa6a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def LDA(sc_corpus, ntopics, genes_dict, genes_shared, cell_gene_list, sc_count_cells, cell_celltype_list, model_dir):\n",
    "    lda = LdaModel(corpus = sc_corpus, num_topics = ntopics, id2word = genes_dict)\n",
    "    if not os.path.exists(model_dir):\n",
    "        os.makedirs(model_dir)\n",
    "    model_file = os.path.join(model_dir, \"lda_model_%s\" %(ntopics))\n",
    "    lda.save(model_file)\n",
    "    # compute the coherence\n",
    "    cm = CoherenceModel(model = lda, corpus = sc_corpus, coherence='u_mass')\n",
    "    umass_coherence = cm.get_coherence()\n",
    "    cm = CoherenceModel(model = lda, corpus = sc_corpus, texts = cell_gene_list, coherence='c_v')\n",
    "    cv_coherence = cm.get_coherence()\n",
    "    # save the topic-cell matrix\n",
    "    topic_cell = lda.get_document_topics(sc_corpus)\n",
    "    topic_cell_mat = gensim.matutils.corpus2csc(topic_cell)\n",
    "    topic_cell_file = os.path.join(model_dir, \"topic_cell_mat_%s.npz\" %(ntopics))\n",
    "    topic_cell_df_file = os.path.join(model_dir, \"topic_cell_mat_%s.txt\" %(ntopics))\n",
    "    scipy.sparse.save_npz(topic_cell_file, topic_cell_mat)\n",
    "    topic_cell_df = pd.DataFrame(topic_cell_mat.todense(), \n",
    "        index = [\"Topic %s\" %i for i in range(1, 1 + topic_cell_mat.shape[0])], \n",
    "        columns = sc_count_cells)\n",
    "    topic_cell_df.to_csv(topic_cell_df_file, sep = \"\\t\", index = True, header = True)\n",
    "    # save the gene-topic matrix\n",
    "    topic_gene_mat_list = lda.get_topics()\n",
    "    topic_gene_mat = np.array(topic_gene_mat_list)\n",
    "    gene_topic_mat = topic_gene_mat.transpose()\n",
    "    gene_topic_mat_list = gene_topic_mat.tolist()\n",
    "    gene_topic_file = os.path.join(model_dir, \"gene_topic_mat_%s.txt\" %(ntopics))\n",
    "    gene_topic_out = open(gene_topic_file, \"w\")\n",
    "    gene_topic_out.write(\"\\t\".join([\"Topic%s\" %i for i in range(1, ntopics + 1)]) + \"\\n\")\n",
    "    for i in range(len(gene_topic_mat_list)):\n",
    "        gene_topic_out.write(genes_shared[i] + \"\\t\" + \"\\t\".join([str(j) for j in gene_topic_mat_list[i]]) + \"\\n\")\n",
    "    gene_topic_out.close()\n",
    "    # convert topic_cell_mat to topic_celltype_mat\n",
    "    celltype_topic_dict = {}\n",
    "    celltype_num_dict = {}\n",
    "    celltypes = sorted(list(set(cell_celltype_list)))\n",
    "    for celltype in celltypes:\n",
    "        celltype_topic_dict[celltype] = [0]*ntopics\n",
    "        celltype_num_dict[celltype] = 0\n",
    "    for i in range(topic_cell_mat.shape[1]):\n",
    "        cell_celltype = cell_celltype_list[i]\n",
    "        celltype_topic_dict[cell_celltype] = [celltype_topic_dict[cell_celltype][j] + topic_cell_mat[j,i] for j in range(topic_cell_mat.shape[0])]\n",
    "        celltype_num_dict[cell_celltype] = celltype_num_dict[cell_celltype] + 1\n",
    "    celltype_topic_mean_dict = {}\n",
    "    for celltype in celltypes:\n",
    "        celltype_topic_mean_dict[celltype] = [i/celltype_num_dict[celltype] for i in celltype_topic_dict[celltype]]\n",
    "    topic_celltype_df = pd.DataFrame(data = celltype_topic_mean_dict)\n",
    "    topic_celltype_file = os.path.join(model_dir,\"topic_celltype_mat_%s.txt\" %(ntopics))\n",
    "    topic_celltype_df.to_csv(topic_celltype_file, sep=\"\\t\")\n",
    "    # return results\n",
    "    res_dict = {\"coherence\": [umass_coherence, cv_coherence], \n",
    "    \"topic_cell_mat\": topic_cell_mat, \n",
    "    \"topic_celltype_df\": topic_celltype_df,\n",
    "    \"celltype_num_dict\": celltype_num_dict}\n",
    "\n",
    "    return(res_dict)\n",
    "\n",
    "def scLDA(sc_count_mat, sc_count_genes, sc_count_cells, cell_celltype_dict,\n",
    "          st_count_mat, st_count_genes, st_count_spots,\n",
    "          normalize, gene_use, ntopics_list, out_dir):\n",
    "    sc_count_genes_array = np.array(sc_count_genes)\n",
    "    sc_count_genes_sorter = np.argsort(sc_count_genes_array)\n",
    "    if normalize:\n",
    "        sc_count_mat = StandardScaler(with_mean=False).fit_transform(sc_count_mat.transpose()).transpose()\n",
    "    if gene_use == \"All\":\n",
    "        genes_shared = list(set(st_count_genes) & set(sc_count_genes))\n",
    "    else:\n",
    "        genes_shared = list(set(st_count_genes) & set(sc_count_genes) & set(gene_use))\n",
    "    genes_shared = sorted(genes_shared)\n",
    "    genes_shared_array = np.array(genes_shared)\n",
    "    genes_shared_index = sc_count_genes_sorter[np.searchsorted(sc_count_genes_array, genes_shared_array, sorter = sc_count_genes_sorter)]\n",
    "    sc_count_mat_use = sc_count_mat[genes_shared_index,:]\n",
    "    cell_gene_list = []\n",
    "    sc_count_mat_use_nonzero = sc_count_mat_use.nonzero()\n",
    "    for i in range(sc_count_mat_use.shape[1]):\n",
    "        gene_ind = sc_count_mat_use_nonzero[0][sc_count_mat_use_nonzero[1] == i]\n",
    "        genes = genes_shared_array[gene_ind].tolist()\n",
    "        cell_gene_list.append(genes)\n",
    "        # evaluate the model\n",
    "    # construct single-cell gene corpus\n",
    "    sc_corpus = gensim.matutils.Sparse2Corpus(sc_count_mat_use)\n",
    "    genes_dict = Dictionary([genes_shared])\n",
    "    genes_dict_file = os.path.join(out_dir, \"Gene_dict.txt\")\n",
    "    genes_dict.save_as_text(genes_dict_file)\n",
    "    cell_celltype_list = []\n",
    "    for i in range(len(sc_count_cells)):\n",
    "        cell_celltype = cell_celltype_dict[sc_count_cells[i]]\n",
    "        cell_celltype_list.append(cell_celltype)\n",
    "    print(\"Selecting the optimal model.\")\n",
    "    model_selection_res = ModelSelect(sc_corpus = sc_corpus, genes_dict = genes_dict, genes_shared = genes_shared,\n",
    "        ntopics_list = ntopics_list, cell_gene_list = cell_gene_list, sc_count_cells = sc_count_cells, \n",
    "        cell_celltype_list = cell_celltype_list, out_dir = out_dir)\n",
    "    model_selected = model_selection_res[\"model\"]\n",
    "    ntopics_selected = model_selection_res[\"ntopics\"]\n",
    "\n",
    "    return({\"genes_dict\": genes_dict, \"model_selected\": model_selected, \"ntopics_selected\": ntopics_selected})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "5af36a01-bfb5-415b-8b8c-146a0fd5eba6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def JS_divergence(p,q):\n",
    "    M = (p+q)/2\n",
    "    return 0.5 * ss.entropy(p,M,base=2) + 0.5*ss.entropy(q,M,base=2)\n",
    "\n",
    "# 矩阵按行求JSD,\n",
    "def JS_divergence_mat(p_mat, q_mat):\n",
    "    raw = p_mat.shape[0]\n",
    "    jsd = 0\n",
    "    for i in range(raw):\n",
    "        jsd += JS_divergence(p_mat.iloc[i], q_mat.iloc[i])\n",
    "    return jsd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca500369-3c45-4eb3-8060-ca1ed453134c",
   "metadata": {},
   "source": [
    "# RUN #"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "10e1ec9e-0837-4dfa-9ef0-e2f0a791de19",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data_dir = '/data/lyx/hubs/SpaTD/stdgcn/benchmark_data/MERFISH/'\n",
    "# idx1 = 1\n",
    "# idx2 = 0.01\n",
    "# res = 50\n",
    "seed=80\n",
    "setup_seed(seed)\n",
    "data_dir = '/data/lyx/hubs/SpaTD/stdgcn/benchmark_data/seqFISH_plus/Dataset2_seqFISHplus_AllenVIsp'\n",
    "prefix = \"seqFISHplus\"\n",
    "res = 200\n",
    "idx1 = 'all'\n",
    "os.chdir('/data/lyx/hubs/SpaTD/stdgcn/benchmark/seqFISH_plus/Dataset2_seqFISHplus_AllenVIsp/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "f447f8f3-ceb2-4bf3-b0b9-841ff7655f0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc_anno = pd.read_table(os.path.join(data_dir,\"sc_data\",\"sc_label.tsv\"))\n",
    "#sc_anno.to_csv(os.path.join(data_dir,\"sc_data\",\"sc_label_for_stride.tsv\"),index=None,header=None,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "052eb141-1434-4d97-9f93-94ccade3200c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sc_count = pd.read_table(os.path.join(data_dir,\"sc_data\",\"MERFISH_ID{0}_{1}_sc_data.tsv\".format(idx1,idx2)),index_col=0)\n",
    "#sc_count.transpose().to_csv(os.path.join(data_dir,\"sc_data\",\"MERFISH_ID{0}_{1}_sc_data_tanspose.tsv\".format(idx1,idx2)) ,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "6b46af71-02d3-463e-9e29-aca754ad8549",
   "metadata": {},
   "outputs": [],
   "source": [
    "st_count = pd.read_table(os.path.join(data_dir,\"ST_data\",\"seqFishplus_Cortex_{0}_data_all.tsv\".format(res)),index_col=0)\n",
    "st_count.transpose().to_csv(os.path.join(data_dir,\"ST_data\",\"seqFishplus_Cortex_{0}_data_all_transpose.tsv\".format(res)) ,sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "43b73a88-50da-43db-a2b2-1149d4401d96",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sc_count_file = os.path.join(data_dir,\"sc_data\",\"MERFISH_ID{0}_{1}_sc_data_tanspose.tsv\".format(idx1,idx2)) \n",
    "# sc_anno_file = os.path.join(data_dir,\"sc_data\",\"sc_label_for_stride.tsv\")\n",
    "# st_count_file = os.path.join(data_dir,\"ST_data\",\"MERFISH_ID{0}_data_{1}_tanspose.tsv\".format(idx1,idx2)) \n",
    "sc_count_file = os.path.join(data_dir,\"sc_data\",'sc_data_transpose.tsv') \n",
    "sc_anno_file = os.path.join(data_dir,\"sc_data\",\"sc_label_for_stride.tsv\")\n",
    "st_count_file = os.path.join(data_dir,\"ST_data\",\"seqFishplus_Cortex_{0}_data_all_transpose.tsv\".format(res)) \n",
    "model_dir = None\n",
    "sc_scale_factor = None\n",
    "st_scale_factor = None\n",
    "out_dir = \"stride\"\n",
    "out_prefix = \"seqFISHplus_dataset2\"\n",
    "normalize = True\n",
    "# gene_use = pd.read_table(os.path.join('/data/lyx/hubs/SpaTD/stdgcn/benchmark/seqFISH_plus/Dataset3_Cortex_allField_77spot/',\n",
    "#                                       \"marker_genes.tsv\"),header=None)[0].to_list()\n",
    "ntopics_list = None\n",
    "\n",
    "if not os.path.exists(out_dir):\n",
    "        os.makedirs(out_dir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "92db047e-0f04-4798-826c-e0fcf81da42f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading ST matrix...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading ST matrix...\")\n",
    "st_info = stProcess(st_count_file, st_scale_factor)\n",
    "st_count_mat = st_info[\"scale_matrix\"]\n",
    "st_count_genes = st_info[\"genes\"]\n",
    "st_count_spots = st_info[\"spots\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "cab7f9b7-2044-482b-9028-9c4e2381bee6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading single-cell count matrix...\n"
     ]
    }
   ],
   "source": [
    "print(\"Reading single-cell count matrix...\")\n",
    "sc_info = scProcess(sc_count_file, sc_anno_file, out_dir, out_prefix, sc_scale_factor)\n",
    "sc_count_scale_mat = sc_info[\"scale_matrix\"]\n",
    "sc_count_raw_mat = sc_info[\"raw_matrix\"]\n",
    "sc_count_genes = sc_info[\"genes\"]\n",
    "sc_count_cells = sc_info[\"cells\"]\n",
    "cell_celltype_dict = sc_info[\"cell_celltype\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d122fd7c-1329-4f0c-9f26-3935d041d34d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Identifying markers...\n"
     ]
    }
   ],
   "source": [
    "print(\"Identifying markers...\")\n",
    "findmarker = True\n",
    "gene_use = MarkerFind(sc_count_raw_mat, sc_count_genes, sc_count_cells, sc_anno_file, ntop = 200)\n",
    "celltypes = set(cell_celltype_dict.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8453d246-b082-4ec5-8ee0-f09980beae1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "ntopics_list = list(range(len(celltypes), 3*len(celltypes)+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "0c70e7e4-6cb5-4d68-9900-a4309cc6090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_count_genes_array = np.array(sc_count_genes)\n",
    "sc_count_genes_sorter = np.argsort(sc_count_genes_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0a94c22d-e40d-45a1-9cb6-3dd877c5522f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_count_mat = StandardScaler(with_mean=False).fit_transform(sc_count_scale_mat.transpose()).transpose()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "83479598-039b-435a-a09a-0fc7627ab858",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1064\n"
     ]
    }
   ],
   "source": [
    "# genes_shared = list(set(st_count_genes) & set(sc_count_genes) & set(gene_use))\n",
    "genes_shared = list(set(st_count_genes) & set(gene_use))\n",
    "print(len(genes_shared))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "cfff9bdc-38ed-4d8e-9025-bbb70b6d22aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "genes_shared = sorted(genes_shared)\n",
    "genes_shared_array = np.array(genes_shared)\n",
    "genes_shared_index = sc_count_genes_sorter[np.searchsorted(sc_count_genes_array, \n",
    "                                                           genes_shared_array, \n",
    "                                                           sorter = sc_count_genes_sorter)]\n",
    "sc_count_mat_use = sc_count_mat[genes_shared_index,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "b873cbfd-25ed-491b-908f-f18adb257e9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_gene_list = []\n",
    "sc_count_mat_use_nonzero = sc_count_mat_use.nonzero()\n",
    "for i in range(sc_count_mat_use.shape[1]):\n",
    "    gene_ind = sc_count_mat_use_nonzero[0][sc_count_mat_use_nonzero[1] == i]\n",
    "    genes = genes_shared_array[gene_ind].tolist()\n",
    "    cell_gene_list.append(genes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "26793534-b3e8-4d10-99ee-0aa77302de69",
   "metadata": {},
   "outputs": [],
   "source": [
    "sc_corpus = gensim.matutils.Sparse2Corpus(sc_count_mat_use)\n",
    "genes_dict = Dictionary([genes_shared])\n",
    "genes_dict_file = os.path.join(out_dir, \"Gene_dict.txt\")\n",
    "genes_dict.save_as_text(genes_dict_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "6788e993-abb4-4f45-86f8-59e1ae847c7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selecting the optimal model.\n"
     ]
    }
   ],
   "source": [
    "cell_celltype_list = []\n",
    "for i in range(len(sc_count_cells)):\n",
    "    cell_celltype = cell_celltype_dict[sc_count_cells[i]]\n",
    "    cell_celltype_list.append(cell_celltype)\n",
    "print(\"Selecting the optimal model.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "4ff6bde5-5d7f-4a00-9abf-abe0095a966c",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training topic model...\n",
      "Selecting the optimal model.\n",
      "Number of topics: 6\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 7\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 8\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 11\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 12\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 13\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 16\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 17\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of topics: 18\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/data/lyx/software/anaconda3/envs/stride/lib/python3.8/site-packages/sklearn/cluster/_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving spatial transcriptomics...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 640x480 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(\"Training topic model...\")\n",
    "lda_res = scLDA(sc_count_scale_mat, sc_count_genes, sc_count_cells, cell_celltype_dict,\n",
    "                st_count_mat, st_count_genes, st_count_spots,\n",
    "                normalize, gene_use, ntopics_list, out_dir)\n",
    "\n",
    "genes_dict = lda_res[\"genes_dict\"]\n",
    "model_selected = lda_res[\"model_selected\"]\n",
    "ntopics_selected = lda_res[\"ntopics_selected\"]\n",
    "model_dir = os.path.join(out_dir, \"model\")\n",
    "print(\"Deconvolving spatial transcriptomics...\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "7446d9fe-25aa-42d1-ab64-2aece30fddb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "metrics_df =pd.read_csv(os.path.join(out_dir, \"Model_selection.txt\"), sep=\"\\t\")\n",
    "model_dir = os.path.join(out_dir, \"model\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "0c1fa65c-befa-4c94-849e-6efb29646a00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Deconvolving spatial transcriptomics...\n"
     ]
    }
   ],
   "source": [
    "print(\"Deconvolving spatial transcriptomics...\")\n",
    "spot_celltype_array_norm_df = SpatialDeconvolve(st_count_mat, st_count_genes, st_count_spots, \n",
    "                                                genes_dict, model_selected, ntopics_selected, \n",
    "                                                normalize, out_dir, model_dir, out_prefix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "aa16cc76-37a4-4a9c-872e-ac287df7a087",
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dir = '/data/lyx/hubs/SpaTD/stdgcn/benchmark/seqFISH_plus/Dataset2_seqFISHplus_AllenVIsp/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "d3037443-ca44-40ca-990e-019ae00380fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot_celltype_array_norm_df.to_csv(\"/data/lyx/hubs/SpaTD/stdgcn/benchmark/MERFISH/ID1/Bregma0.01/stride_predict_result.csv\")\n",
    "spot_celltype_array_norm_df.to_csv(os.path.join(out_dir, \"stride_predict_result_seed{}.csv\".format(seed)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "42dc8955-366a-487d-97b7-ad891f4d9346",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Astrocyte', 'Endothelial', 'Excitatory_neuron', 'Interneuron',\n",
       "       'Microglia', 'Oligodendrocyte'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_proportion= pd.read_csv(os.path.join(out_dir, \"stride_predict_result_seed{}.csv\".format(seed)),index_col=0)\n",
    "pred_proportion.columns = ['Astrocyte', 'Endothelial', 'Excitatory_neuron', 'Interneuron',\n",
    "       'Microglia', 'Oligodendrocyte']\n",
    "#pd.read_csv('./benchmark/MERFISH/ID1/Bregma0.01/SONAR.results.csv',index_col=0)\n",
    "import pandas as pd\n",
    "columns = pd.Index(pred_proportion.columns, dtype='object')\n",
    "columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "7bba8e90-855f-4af4-a02c-1b8dfef5009f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Astrocyte</th>\n",
       "      <th>Endothelial</th>\n",
       "      <th>Excitatory_neuron</th>\n",
       "      <th>Interneuron</th>\n",
       "      <th>Microglia</th>\n",
       "      <th>Oligodendrocyte</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>gr_27</th>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.571429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.071429</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gr_24</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.100000</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gr_26</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.222222</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gr_36</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>0.125000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gr_35</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.111111</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Astrocyte  Endothelial  Excitatory_neuron  Interneuron  Microglia  \\\n",
       "gr_27   0.071429     0.071429           0.571429     0.071429   0.071429   \n",
       "gr_24   0.000000     0.000000           0.700000     0.100000   0.200000   \n",
       "gr_26   0.000000     0.000000           0.777778     0.000000   0.000000   \n",
       "gr_36   0.000000     0.125000           0.750000     0.125000   0.000000   \n",
       "gr_35   0.000000     0.111111           0.777778     0.000000   0.000000   \n",
       "\n",
       "       Oligodendrocyte  \n",
       "gr_27         0.142857  \n",
       "gr_24         0.000000  \n",
       "gr_26         0.222222  \n",
       "gr_36         0.000000  \n",
       "gr_35         0.111111  "
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# real_proportion = pd.read_csv('./benchmark_data/MERFISH/ST_data/MERFISH_ID1_ground_truth_0.01.tsv', sep='\\t')\n",
    "real_proportion = pd.read_table(os.path.join(data_dir,'ST_data',\"seqFishplus_Cortex_200_ground_truth_all.tsv\"),index_col=0)\n",
    "#real_proportion = pd.DataFrame(data=real_proportion_raw.iloc[:, 4:].values,columns=columns,index=real_proportion_raw.iloc[:, 0])\n",
    "real_proportion = real_proportion[columns]\n",
    "real_proportion.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "982d0deb-8c78-4f1f-8570-65b8c8fa82aa",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1.1370986515816737"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse_by_K = 0\n",
    "rmse_list = []\n",
    "for column in columns:\n",
    "    _sum = np.sum(np.square(pred_proportion[column]-real_proportion[column]))\n",
    "    rmse_by_K += _sum\n",
    "    rmse_list.append(_sum)\n",
    "rmse_by_K /= len(columns)\n",
    "rmse_by_K = np.sqrt(rmse_by_K)\n",
    "rmse_by_K "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "d162dabe-3394-4147-a91f-012ef2c4da4e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.15700883411234634"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "JSD = JS_divergence_mat(pred_proportion, real_proportion)/pred_proportion.shape[0]\n",
    "JSD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "1e205a22-e606-4c2d-9cf9-c7ab04c798de",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.45495260867018983"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pcc_by_K = 0\n",
    "pcc_list=[]\n",
    "for column in columns:\n",
    "    _sum = np.corrcoef(pred_proportion[column],real_proportion[column])[0][1]\n",
    "    pcc_by_K +=_sum\n",
    "    pcc_list.append(_sum)\n",
    "pcc_by_K /=len(columns)\n",
    "pcc_by_K"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "0b85a780-a2b3-4ba3-8c14-3f0b802f78fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(zip(columns,rmse_list,pcc_list),columns=['cell_type','RMSE','PCC']).to_csv(os.path.join(out_dir,'stride_celltype_predict_result_seed{}.csv').format(seed))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "abc58428-6a2c-4bac-8398-502af833c1f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('/data/lyx/hubs/SpaTD/stdgcn/benchmark/final_stat.txt','a+') as df:\n",
    "    #df.write('data\\tseed\\tRMSE\\tPCC\\tJSD\\n')\n",
    "    df.write('{}\\t{}\\t{}\\t{}\\t{}\\n'.format(data_dir.split('/')[-1],seed,rmse_by_K,pcc_by_K,JSD))\n",
    "df.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "7205c50b-1730-476e-ae40-944373d0b1ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/data/lyx/hubs/SpaTD/stdgcn/benchmark/seqFISH_plus/Dataset2_seqFISHplus_AllenVIsp/'"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0efabcbc-8de9-497d-9b8c-08fade0ad5ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "cd"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stride",
   "language": "python",
   "name": "stride"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
