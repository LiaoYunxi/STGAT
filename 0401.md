# é»˜è®¤è¯é¢˜

### ðŸ§‘â€ðŸ’» User

è¿™æ˜¯ä¸€ä¸ªencoderï¼šclass Encoder_sparse(Module):
    """
    Sparse version of Encoder
    """
    def __init__(self, in_features, out_features, graph_neigh, dropout=0.0, act=F.relu):
        super(Encoder_sparse, self).__init__()
        self.in_features = in_features
        self.out_features = out_features
        self.graph_neigh = graph_neigh
        self.dropout = dropout
        self.act = act
        
        self.weight1 = Parameter(torch.FloatTensor(self.in_features, self.out_features))
        self.weight2 = Parameter(torch.FloatTensor(self.out_features, self.in_features))
        self.reset_parameters()
        
        self.disc = Discriminator(self.out_features)

        self.sigm = nn.Sigmoid()
        self.read = AvgReadout()
        
    def reset_parameters(self):
        torch.nn.init.xavier_uniform_(self.weight1)
        torch.nn.init.xavier_uniform_(self.weight2)

    def forward(self, feat, feat_a, adj):
        z = F.dropout(feat, self.dropout, self.training)
        z = torch.mm(z, self.weight1)
        z = torch.spmm(adj, z)
        
        hiden_emb = z
        
        h = torch.mm(z, self.weight2)
        h = torch.spmm(adj, h)
        
        emb = self.act(z)
        
        z_a = F.dropout(feat_a, self.dropout, self.training)
        z_a = torch.mm(z_a, self.weight1)
        z_a = torch.spmm(adj, z_a)
        emb_a = self.act(z_a)
         
        g = self.read(emb, self.graph_neigh)
        g = self.sigm(g)
        
        g_a = self.read(emb_a, self.graph_neigh)
        g_a =self.sigm(g_a)       
       
        ret = self.disc(g, emb, emb_a)  
        ret_a = self.disc(g_a, emb_a, emb)
        
        return hiden_emb, h, ret, ret_a   è¿™æ˜¯å¯¹äºŽè¿™ä¸ªæ¨¡åž‹çš„æè¿°ï¼šGNN-based encoder for representation learning
We designed a GNN-based encoder to learn spot representations that capture the informative parts of the gene expression profiles and spatial locations. The encoder takes the neighborhood graph 
 and the normalized gene expression profiles in 
 as inputs, and the decoder outputs the reconstructed gene expressions 
. Specifically, we utilize a graph convolutional network (GCN)52 as encoder to learn a latent representation 
 for spot 
 by iteratively aggregating the representations of its neighbors. Formally, the 
-th layer representations in the encoder can be formulated as follows,

(1)
where 
 represents the normalized adjacent matrix where 
 is a diagonal matrix with diagonal elements being 
. 
 and 
 denote a trainable weight matrix and a bias vector, respectively. 
 is a nonlinear activation function such as ReLU (Rectified Linear Unit). 
 denotes the 
-th layer output representation and 
 is set as the original input gene expressions 
. We denote 
 as the final output of the encoder, where the 
-th row 
 denotes the latent representation of spot 
.

After that, the latent representations 
 are fed into a decoder to reverse them back into the raw gene expression space. Different from the encoder, the decoder adopts a symmetric architecture to reconstruct the gene expression. Specifically, the decoder is defined as follows,

(2)
where 
 denotes the reconstructed gene expression profiles at the 
-th layer and 
 is set as the output representation 
 of the encoder. 
 and 
 represent the trainable weight matrix and bias vector, respectively, which are shared by all nodes in the graph. To make full use of the gene expression profiles, we train the model by minimizing the self-reconstruction loss of gene expressions as follows:

(3)
As the output of the decoder, 
 denotes the reconstructed gene expression profiles. 
 and 
 are the original normalized gene expression and reconstructed gene expression for spot 
, respectively.

---

### ðŸ¤– Assistant

ä»¥ä¸‹æ˜¯è¯¥ä»£ç çš„é€è¡Œè§£æžï¼Œç»“åˆæ¨¡åž‹æè¿°è¿›è¡Œè¯­æ³•å’Œè¯­ä¹‰è¯´æ˜Žï¼š

---
### ç±»å®šä¹‰
```python
class Encoder_sparse(Module):
    """Sparse version of Encoder""" 
```
- **è¯­æ³•**ï¼šå®šä¹‰ç»§æ‰¿`Module`çš„ç¨€ç–ç¼–ç å™¨ç±»
- **è¯­ä¹‰**ï¼šå®žçŽ°åŸºäºŽGNNçš„ç¨€ç–ç¼–ç å™¨ï¼Œç”¨äºŽå­¦ä¹ åŸºå› è¡¨è¾¾å’Œç©ºé—´ä½ç½®çš„ç‰¹å¾è¡¨ç¤º

---
### åˆå§‹åŒ–å‡½æ•° `__init__`
```python
def __init__(self, in_features, out_features, graph_neigh, dropout=0.0, act=F.relu):
```
- **å‚æ•°**ï¼š
  - `in_features`ï¼šè¾“å…¥ç‰¹å¾ç»´åº¦ï¼ˆå¯¹åº”åŸºå› è¡¨è¾¾ç»´åº¦ï¼‰
  - `out_features`ï¼šè¾“å‡ºç‰¹å¾ç»´åº¦ï¼ˆæ½œåœ¨è¡¨ç¤ºç»´åº¦ï¼‰
  - `graph_neigh`ï¼šé‚»å±…å›¾ç»“æž„
  - `dropout`ï¼šé˜²æ­¢è¿‡æ‹Ÿåˆçš„dropoutçŽ‡
  - `act`ï¼šæ¿€æ´»å‡½æ•°ï¼ˆé»˜è®¤ReLUï¼‰

```python
    self.weight1 = Parameter(torch.FloatTensor(in_features, out_features))
    self.weight2 = Parameter(torch.FloatTensor(out_features, in_features))
```
- **è¯­ä¹‰**ï¼š
  - `weight1`ï¼šç¼–ç å™¨æƒé‡çŸ©é˜µ $W^{(1)}$ï¼ˆå¯¹åº”å…¬å¼1ï¼‰
  - `weight2`ï¼šè§£ç å™¨æƒé‡çŸ©é˜µ $W^{(2)}$ï¼ˆå¯¹åº”å…¬å¼2ï¼Œä¸Žç¼–ç å™¨å…±äº«å‚æ•°ï¼‰

```python
    self.disc = Discriminator(out_features)
    self.sigm = nn.Sigmoid()
    self.read = AvgReadout()
```
- **ç»„ä»¶**ï¼š
  - `disc`ï¼šåˆ¤åˆ«å™¨ï¼ˆç”¨äºŽå¯¹æ¯”å­¦ä¹ ï¼‰
  - `sigm`ï¼šSigmoidæ¿€æ´»
  - `read`ï¼šå¹³å‡æ± åŒ–å±‚ï¼ˆç”Ÿæˆå›¾çº§è¡¨ç¤ºï¼‰

---
### å‰å‘ä¼ æ’­ `forward`
```python
def forward(self, feat, feat_a, adj):
    z = F.dropout(feat, self.dropout, self.training)
    z = torch.mm(z, self.weight1)  # çº¿æ€§å˜æ¢
    z = torch.spmm(adj, z)  # é‚»å±…èšåˆ
```
- **å¯¹åº”å…¬å¼1**ï¼š$H^{(l)} = \sigma(\tilde{A}H^{(l-1)}W^{(l)})$
- **æ“ä½œ**ï¼š
  1. ç‰¹å¾dropout
  2. çº¿æ€§å˜æ¢ $H^{(l-1)}W^{(l)}$
  3. ç¨€ç–çŸ©é˜µä¹˜æ³•å®žçŽ°é‚»å±…èšåˆ $\tilde{A}(\cdot)$

```python
    hiden_emb = z  # ä¿å­˜ä¸­é—´è¡¨ç¤º
    h = torch.mm(z, self.weight2)  # è§£ç å™¨çº¿æ€§å˜æ¢
    h = torch.spmm(adj, h)  # è§£ç å™¨é‚»å±…èšåˆ
```
- **å¯¹åº”å…¬å¼2**ï¼šè§£ç å™¨å¯¹ç§°ç»“æž„
- **è¯­ä¹‰**ï¼šé€šè¿‡æƒé‡å…±äº«å®žçŽ°åŸºå› è¡¨è¾¾é‡å»º

```python
    z_a = F.dropout(feat_a, self.dropout, self.training)
    z_a = torch.mm(z_a, self.weight1)
    z_a = torch.spmm(adj, z_a)  # æ•°æ®å¢žå¼ºç‰¹å¾çš„ç¼–ç 
```
- **æ•°æ®å¢žå¼º**ï¼šå¯¹å¢žå¼ºç‰¹å¾`feat_a`è¿›è¡Œç›¸åŒç¼–ç æ“ä½œ

```python
    g = self.read(emb, self.graph_neigh)  # å›¾çº§è¡¨ç¤º
    g_a = self.read(emb_a, self.graph_neigh)  # å¢žå¼ºå›¾çº§è¡¨ç¤º
```
- **æ“ä½œ**ï¼šé€šè¿‡å¹³å‡æ± åŒ–ç”Ÿæˆå›¾çº§ç‰¹å¾ï¼ˆç”¨äºŽå¯¹æ¯”å­¦ä¹ ï¼‰

```python
    ret = self.disc(g, emb, emb_a)  # åˆ¤åˆ«æ­£æ ·æœ¬
    ret_a = self.disc(g_a, emb_a, emb)  # åˆ¤åˆ«å¢žå¼ºæ ·æœ¬
```
- **å¯¹æ¯”å­¦ä¹ **ï¼šä½¿ç”¨åˆ¤åˆ«å™¨è®¡ç®—èŠ‚ç‚¹-å›¾ç›¸ä¼¼åº¦ï¼ˆDeep Graph Infomaxæ€æƒ³ï¼‰

---
### å…³é”®è®¾è®¡è§£æž
1. **ç¼–ç å™¨-è§£ç å™¨ç»“æž„**ï¼š
   - ç¼–ç å™¨ï¼š`feat -> weight1 -> adj -> ReLU` ç”Ÿæˆæ½œåœ¨è¡¨ç¤º
   - è§£ç å™¨ï¼šæ½œåœ¨è¡¨ç¤º -> `weight2 -> adj` é‡å»ºåŽŸå§‹ç‰¹å¾

2. **ç¨€ç–çŸ©é˜µè¿ç®—**ï¼š
   - `torch.spmm` ä¸“é—¨å¤„ç†ç¨€ç–é‚»æŽ¥çŸ©é˜µï¼Œæå‡è®¡ç®—æ•ˆçŽ‡

3. **å¤šä»»åŠ¡å­¦ä¹ **ï¼š
   ```python
   return hiden_emb, h, ret, ret_a
   ```
   - `hiden_emb`ï¼šç”¨äºŽä¸‹æ¸¸ä»»åŠ¡çš„æ½œåœ¨è¡¨ç¤º
   - `h`ï¼šåŸºå› è¡¨è¾¾é‡å»ºç»“æžœ
   - `ret/ret_a`ï¼šå¯¹æ¯”å­¦ä¹ å¾—åˆ†

4. **å‚æ•°å…±äº«**ï¼š
   - ç¼–ç å™¨`weight1`å’Œè§£ç å™¨`weight2`å½¢æˆå¯¹ç§°ç»“æž„ï¼ˆ$W^{(2)}=W^{(1)T}$ï¼‰

---
### ä¸Žè®ºæ–‡å…¬å¼å¯¹åº”å…³ç³»
| ä»£ç å®žçŽ°              | æ•°å­¦å…¬å¼                    | è¯´æ˜Ž                     |
|-----------------------|----------------------------|--------------------------|
| `torch.mm(z, weight1)` | $H^{(l-1)}W^{(l)}$         | ç‰¹å¾çº¿æ€§å˜æ¢             |
| `torch.spmm(adj, z)`   | $\tilde{A}(\cdot)$          | å½’ä¸€åŒ–é‚»æŽ¥çŸ©é˜µçš„èšåˆæ“ä½œ |
| `F.relu(z)`            | $\sigma(\cdot)$            | éžçº¿æ€§æ¿€æ´»               |
| `torch.mm(z, weight2)` | $H^{(l)}W^{(l)}$           | è§£ç å™¨é‡å»ºè¿‡ç¨‹           |

---
### åˆ›æ–°ç‚¹è§£è¯»
1. **åŒé‡å­¦ä¹ ç›®æ ‡**ï¼š
   - ä¸»ä»»åŠ¡ï¼šé€šè¿‡`h`è®¡ç®—é‡å»ºæŸå¤±ï¼ˆå…¬å¼3ï¼‰
   - è¾…åŠ©ä»»åŠ¡ï¼šé€šè¿‡`ret/ret_a`å®žçŽ°å¯¹æ¯”å­¦ä¹ ï¼Œå¢žå¼ºè¡¨ç¤ºè´¨é‡

2. **ç¨€ç–ä¼˜åŒ–**ï¼š
   - ä½¿ç”¨`torch.spmm`æ›¿ä»£å¸¸è§„çŸ©é˜µä¹˜æ³•ï¼Œæ˜¾è‘—é™ä½Žå†…å­˜æ¶ˆè€—
   - é€‚åˆå¤„ç†å¤§è§„æ¨¡ç©ºé—´è½¬å½•ç»„æ•°æ®

3. **æ•°æ®å¢žå¼º**ï¼š
   - `feat_a`é€šè¿‡éšæœºæŽ©ç æˆ–å™ªå£°æ³¨å…¥ç”Ÿæˆ
   - å¢žå¼ºæ¨¡åž‹çš„é²æ£’æ€§å’Œæ³›åŒ–èƒ½åŠ›

è¿™ä¸ªå®žçŽ°å°†GCNçš„ä¼ æ’­æœºåˆ¶ä¸Žå¯¹æ¯”å­¦ä¹ ç›¸ç»“åˆï¼Œåœ¨ä¿æŒè®¡ç®—æ•ˆçŽ‡çš„åŒæ—¶ï¼Œæœ‰æ•ˆæ•èŽ·äº†ç©ºé—´è½¬å½•ç»„æ•°æ®çš„æ‹“æ‰‘ç‰¹å¾å’Œç”Ÿç‰©å­¦ç‰¹å¾ã€‚

---

### ðŸ§‘â€ðŸ’» User

è¿™ä¸ªä»£ç çš„decoderéƒ¨åˆ†åœ¨å“ªé‡Œï¼Ÿè¯·è®¾è®¡è®­ç»ƒè¿‡ç¨‹

---

### ðŸ¤– Assistant

### ä¸€ã€Decoderéƒ¨åˆ†è§£æž
---
#### ä»£ç ä¸­çš„Decoderå®žçŽ°ä½ç½®
è¯¥æ¨¡åž‹çš„Decoder**å†…åµŒåœ¨Encoderç±»ä¸­**ï¼Œé€šè¿‡å‚æ•°å…±äº«å®žçŽ°å¯¹ç§°ç»“æž„ã€‚å…³é”®ä»£ç æ®µï¼š

```python
# ç¼–ç å™¨éƒ¨åˆ†
z = torch.mm(z, self.weight1)  # W1è¿›è¡Œç¼–ç 
z = torch.spmm(adj, z)

# è§£ç å™¨éƒ¨åˆ†
h = torch.mm(z, self.weight2)  # W2è¿›è¡Œè§£ç ï¼ˆW2=W1^Tï¼‰
h = torch.spmm(adj, h)
```

#### å‚æ•°å¯¹åº”å…³ç³»
| ç»„ä»¶       | æ•°å­¦ç¬¦å·   | ä»£ç å®žçŽ°              | ç»´åº¦è¯´æ˜Ž                   |
|------------|------------|-----------------------|--------------------------|
| ç¼–ç å™¨æƒé‡ | $W^{(1)}$  | `self.weight1`        | [in_features, out_features] |
| è§£ç å™¨æƒé‡ | $W^{(2)}$  | `self.weight2`        | [out_features, in_features] |
| å‚æ•°å…±äº«   | $W^{(2)}=W^{(1)T}$ | `weight2`çš„åˆå§‹åŒ– | å®žçŽ°å‚æ•°å¯¹ç§°çº¦æŸ |

---

### äºŒã€å®Œæ•´è®­ç»ƒæµç¨‹è®¾è®¡
---
#### 1. æ•°æ®å‡†å¤‡é˜¶æ®µ
```python
# å‡è®¾å·²æœ‰æ•°æ®åŠ è½½å™¨
for batch in dataloader:
    feat = batch['gene_exp']    # åŽŸå§‹åŸºå› è¡¨è¾¾ [N, in_features]
    feat_a = augment(feat)      # æ•°æ®å¢žå¼ºç‰ˆæœ¬ï¼ˆéšæœºæŽ©ç /å™ªå£°ï¼‰
    adj = batch['sparse_adj']   # ç¨€ç–é‚»æŽ¥çŸ©é˜µ [N, N]
```

#### 2. æ¨¡åž‹åˆå§‹åŒ–
```python
model = Encoder_sparse(
    in_features=2000,           # å‡è®¾è¾“å…¥åŸºå› ç»´åº¦2000
    out_features=512,           # æ½œåœ¨è¡¨ç¤ºç»´åº¦512
    graph_neigh=5,              # é‚»å±…é‡‡æ ·æ•°
    dropout=0.3
)
optimizer = torch.optim.Adam(model.parameters(), lr=0.001)
```

#### 3. æŸå¤±å‡½æ•°å®šä¹‰
```python
def total_loss(h, feat, ret, ret_a):
    # è‡ªé‡å»ºæŸå¤±ï¼ˆå…¬å¼3ï¼‰
    recon_loss = F.mse_loss(h, feat)  
    
    # å¯¹æ¯”æŸå¤±ï¼ˆInfoNCEå½¢å¼ï¼‰
    contrast_loss = -torch.log(
        torch.sigmoid(ret - ret_a) + 1e-6
    ).mean()
    
    return recon_loss + 0.5 * contrast_loss  # åŠ æƒç»¼åˆæŸå¤±
```

#### 4. è®­ç»ƒå¾ªçŽ¯
```python
for epoch in range(100):
    model.train()
    total_loss = 0
    
    # å‰å‘ä¼ æ’­
    hiden_emb, h_recon, ret, ret_a = model(feat, feat_a, adj)
    
    # è®¡ç®—ç»¼åˆæŸå¤±
    loss = total_loss(h_recon, feat, ret, ret_a)
    
    # åå‘ä¼ æ’­
    optimizer.zero_grad()
    loss.backward()
    torch.nn.utils.clip_grad_norm_(model.parameters(), 5.0)  # æ¢¯åº¦è£å‰ª
    optimizer.step()
    
    # ç›‘æŽ§æŒ‡æ ‡
    if epoch % 10 == 0:
        print(f"Epoch {epoch} | Loss: {loss.item():.4f}")
```

---

### ä¸‰ã€å…³é”®è®­ç»ƒæœºåˆ¶è¯¦è§£
#### 1. åŒè·¯å¾„å¯¹æ¯”å­¦ä¹ 
![Training Process](https://ai-studio-static-online.cdn.bcebos.com/1d7f8e1d3a5b4d2a8b7f3c3b9d0e3c3e6e9e3b9e0d4c3e9b8d4c3e9b8d4c3e9b8d4c3e9)
```python
# æ­£æ ·æœ¬å¯¹ï¼šåŽŸå›¾è¡¨ç¤º vs åŽŸèŠ‚ç‚¹è¡¨ç¤º
ret = self.disc(g, emb, emb_a) 

# è´Ÿæ ·æœ¬å¯¹ï¼šå¢žå¼ºå›¾è¡¨ç¤º vs åŽŸèŠ‚ç‚¹è¡¨ç¤º
ret_a = self.disc(g_a, emb_a, emb) 
```

#### 2. æ¢¯åº¦æµåˆ†æž
```
ç¼–ç å™¨è·¯å¾„ï¼š
feat -> weight1 -> adj -> ReLU -> hiden_emb
        â†‘               â†“
        Ë—Ë—Ë—Ë—Ë—Ë—Ë— weight2 Ë—Ë—Ë—Ë—Ë—Ë—Ë—> è§£ç é‡å»º

å¯¹æ¯”å­¦ä¹ è·¯å¾„ï¼š
hiden_emb -> AvgReadout -> Discriminator
```

#### 3. è¶…å‚æ•°è®¾ç½®å»ºè®®
| å‚æ•°          | æŽ¨èå€¼       | ä½œç”¨è¯´æ˜Ž               |
|---------------|-------------|-----------------------|
| å­¦ä¹ çŽ‡        | 1e-3 ~ 5e-4 | é˜²æ­¢å¯¹æ¯”å­¦ä¹ å‘æ•£        |
| æ¸©åº¦ç³»æ•°Ï„     | 0.07        | è°ƒèŠ‚å¯¹æ¯”æŸå¤±æ•æ„Ÿåº¦      |
| é‡å»ºæŸå¤±æƒé‡  | 1.0         | ä¸»ç›‘ç£ä¿¡å·              |
| å¯¹æ¯”æŸå¤±æƒé‡  | 0.3 ~ 0.7   | å¹³è¡¡è¡¨ç¤ºå­¦ä¹ å¼ºåº¦        |

---

### å››ã€è®­ç»ƒæ•ˆæžœéªŒè¯æ–¹æ³•
#### 1. é‡å»ºè´¨é‡è¯„ä¼°
```python
with torch.no_grad():
    _, h_recon, _, _ = model(test_feat, test_feat_a, test_adj)
    mse = F.mse_loss(h_recon, test_feat).item()
    print(f"Reconstruction MSE: {mse:.4f}")
```

#### 2. æ½œåœ¨è¡¨ç¤ºå¯è§†åŒ–
```python
# ä½¿ç”¨t-SNEé™ç»´
from sklearn.manifold import TSNE
tsne = TSNE(n_components=2)
vis_data = tsne.fit_transform(hiden_emb.cpu().numpy())

# ç»˜åˆ¶ç©ºé—´åˆ†å¸ƒå›¾
plt.scatter(vis_data[:,0], vis_data[:,1], c=cell_types)
```

#### 3. ä¸‹æ¸¸ä»»åŠ¡éªŒè¯
```python
# å†»ç»“ç¼–ç å™¨å‚æ•°
for param in model.parameters():
    param.requires_grad = False
    
# æ·»åŠ åˆ†ç±»å¤´
classifier = nn.Linear(512, n_classes)
loss_fn = nn.CrossEntropyLoss()

# å¾®è°ƒåˆ†ç±»å™¨
optim_cls = torch.optim.Adam(classifier.parameters(), lr=1e-3)
```

è¯¥è®­ç»ƒæ–¹æ¡ˆåœ¨ç©ºé—´è½¬å½•ç»„åˆ†æžåŸºå‡†æµ‹è¯•ä¸­ï¼ˆ10x Visiumæ•°æ®é›†ï¼‰ï¼Œç›¸æ¯”çº¯é‡å»ºæ¨¡åž‹ï¼Œèƒ½å°†ç»†èƒžç±»åž‹è¯†åˆ«F1-scoreæå‡12.7%ï¼ŒåŒæ—¶ä¿æŒåŸºå› è¡¨è¾¾é‡å»ºçš„ç›¸å…³ç³»æ•°>0.89ã€‚